{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNLjfwxmwPdjZ5KlQxvQq1B"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","# Question 1: Calculating Information Gain for a Decision Tree Classification Problem\n","\n","You are given a dataset of numerical features and a target variable indicating whether a tennis game will be played. The dataset has the following attributes: Temperature, Humidity, and WindSpeed. The target variable is PlayTennis. The dataset is as follows:\n","\n","| Temperature | Humidity | WindSpeed | PlayTennis |\n","|-------------|----------|-----------|------------|\n","| 85          | 85       | 5         | No         |\n","| 80          | 90       | 10        | No         |\n","| 78          | 95       | 5         | Yes        |\n","| 72          | 80       | 5         | Yes        |\n","| 69          | 70       | 10        | Yes        |\n","| 75          | 80       | 15        | No         |\n","\n","1. **Calculate the entropy of the target variable PlayTennis.**\n","\n","2. **Choose a threshold for splitting the attribute \"Temperature\" and calculate the information gain for this split. Use the threshold \\( T = 75 \\) (i.e., split the data into subsets where Temperature <= 75 and Temperature > 75).**\n","\n","3. **Determine which attribute would be the best to split on first based on the highest information gain among the attributes Temperature \\( T = 75 \\), Humidity \\( H = 85 \\), and WindSpeed \\( W = 10 \\).**\n","\n","### Solution Outline\n","\n","1. **Entropy of PlayTennis:**\n","\n","   Entropy is calculated using the formula:\n","   $\n","   H(S) = - \\sum_{i=1}^{c} p_i \\log_2(p_i)\n","   $\n","   where \\(c\\) is the number of classes and \\(p_i\\) is the probability of class \\(i\\).\n","\n","2. **Information Gain for Temperature:**\n","\n","   - Split the dataset based on the threshold \\( T = 75 \\).\n","   - Calculate the entropy of each subset.\n","   - Calculate the weighted average entropy of the subsets.\n","   - Information gain is calculated using the formula:\n","   $\n","   IG(S, A) = H(S) - \\sum_{v \\in \\text{Values}(A)} \\frac{|S_v|}{|S|} H(S_v)\n","   $\n","   where \\(S_v\\) is the subset of \\(S\\) for which attribute \\(A\\) has value \\(v\\).\n","\n","3. **Calculating Information Gain for all attributes and determining the best attribute to split:**\n","\n","   Repeat the above process for Humidity and WindSpeed using appropriate thresholds. Compare the information gains and select the attribute with the highest information gain.\n"],"metadata":{"id":"jjmW064MJ4dN"}},{"cell_type":"markdown","source":["# Question 2: Calculating Information Gain for a Decision Tree Regression Problem\n","\n","You are given a dataset of numerical features and a target variable indicating the house prices. The dataset has the following attributes: Size (in square feet), Number of Bedrooms, and Age (in years). The target variable is Price (in $1000s). The dataset is as follows:\n","\n","| Size (sqft) | Bedrooms | Age (years) | Price ($1000s) |\n","|-------------|----------|-------------|----------------|\n","| 2100        | 3        | 30          | 400            |\n","| 1600        | 2        | 20          | 330            |\n","| 2400        | 4        | 15          | 369            |\n","| 1416        | 3        | 40          | 232            |\n","| 3000        | 4        | 8           | 540            |\n","| 1985        | 3        | 30          | 260            |\n","\n","\n","1. **Calculate the variance of the target variable Price.**\n","\n","2. **Choose a threshold for splitting the attribute \"Size\" and calculate the information gain for this split. Use the threshold \\( S = 2000 \\) (i.e., split the data into subsets where Size â‰¤ 2000 and Size > 2000).**\n","\n","---\n","\n","### Solution Outline:\n","\n","1. **Variance of Price:**\n","\n","   Variance is calculated using the formula:\n","   $\n","   \\text{Var}(S) = \\frac{1}{N} \\sum_{i=1}^{N} (x_i - \\bar{x})^2\n","   $\n","   where \\(N\\) is the number of samples, \\(x_i\\) is the value of the target variable for the \\(i\\)-th sample, and $(\\bar{x})$ is the mean of the target variable.\n","\n","2. **Information Gain for Size:**\n","\n","   - Split the dataset based on the threshold \\( S = 2000 \\).\n","   - Calculate the variance of each subset.\n","   - Calculate the weighted average variance of the subsets.\n","   - Information gain is calculated using the formula:\n","   $\n","   IG(S, A) = \\text{Var}(S) - \\sum_{v \\in \\text{Values}(A)} \\frac{|S_v|}{|S|} \\text{Var}(S_v)\n","   $\n","   where \\(S_v\\) is the subset of \\(S\\) for which attribute \\(A\\) has value \\(v\\).\n"],"metadata":{"id":"2iK6-zBTrQ4y"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y7_gu34_Jumo"},"outputs":[],"source":[]}]}