{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO9hCePfQxU0D6tUYNkoqiD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","# Question 1: Calculating Information Gain for a Decision Tree Classification Problem\n","\n","You are given a dataset of numerical features and a target variable indicating whether a tennis game will be played. The dataset has the following attributes: Temperature, Humidity, and WindSpeed. The target variable is PlayTennis. The dataset is as follows:\n","\n","| Temperature | Humidity | WindSpeed | PlayTennis |\n","|-------------|----------|-----------|------------|\n","| 85          | 85       | 5         | No         |\n","| 80          | 90       | 10        | No         |\n","| 78          | 95       | 5         | Yes        |\n","| 72          | 80       | 5         | Yes        |\n","| 69          | 70       | 10        | Yes        |\n","| 75          | 80       | 15        | No         |\n","\n","1. **Calculate the entropy of the target variable PlayTennis.**\n","\n","2. **Choose a threshold for splitting the attribute \"Temperature\" and calculate the information gain for this split. Use the threshold \\( T = 75 \\) (i.e., split the data into subsets where Temperature <= 75 and Temperature > 75).**\n","\n","3. **Determine which attribute would be the best to split on first based on the highest information gain among the attributes Temperature \\( T = 75 \\), Humidity \\( H = 85 \\), and WindSpeed \\( W = 10 \\).**\n","\n","### Solution Outline\n","\n","1. **Entropy of PlayTennis:**\n","\n","   Entropy is calculated using the formula:\n","   $\n","   H(S) = - \\sum_{i=1}^{c} p_i \\log_2(p_i)\n","   $\n","   where \\(c\\) is the number of classes and \\(p_i\\) is the probability of class \\(i\\).\n","\n","2. **Information Gain for Temperature:**\n","\n","   - Split the dataset based on the threshold \\( T = 75 \\).\n","   - Calculate the entropy of each subset.\n","   - Calculate the weighted average entropy of the subsets.\n","   - Information gain is calculated using the formula:\n","   $\n","   IG(S, A) = H(S) - \\sum_{v \\in \\text{Values}(A)} \\frac{|S_v|}{|S|} H(S_v)\n","   $\n","   where \\(S_v\\) is the subset of \\(S\\) for which attribute \\(A\\) has value \\(v\\).\n","\n","3. **Calculating Information Gain for all attributes and determining the best attribute to split:**\n","\n","   Repeat the above process for Humidity and WindSpeed using appropriate thresholds. Compare the information gains and select the attribute with the highest information gain.\n"],"metadata":{"id":"jjmW064MJ4dN"}},{"cell_type":"markdown","source":["# Solution\n","\n","### 1. Calculate the entropy of the target variable PlayTennis\n","\n","The entropy \\( H(S) \\) of the target variable \\(PlayTennis\\) can be calculated using the formula:\n","$ H(S) = - \\sum_{i=1}^{c} p_i \\log_2(p_i) $\n","\n","where \\(c\\) is the number of classes and \\(p_i\\) is the probability of class \\(i\\).\n","\n","In our dataset:\n","- Number of \"Yes\" (PlayTennis = Yes) = 3\n","- Number of \"No\" (PlayTennis = No) = 3\n","- Total samples = 6\n","\n","So, the probabilities are:\n","\n","$ p(Yes) = \\frac{3}{6} = 0.5 $\n","\n","$ p(No) = \\frac{3}{6} = 0.5 $\n","\n","The entropy is:\n","\n","$ H(S) = - (0.5 \\log_2 0.5 + 0.5 \\log_2 0.5) \\$\n","\n","$ H(S) = - (0.5 \\times -1 + 0.5 \\times -1) $\n","\n","$ H(S) = - (-0.5 - 0.5) $\n","\n","$ H(S) = 1 $\n","\n","### 2. Choose a threshold for splitting the attribute \"Temperature\" and calculate the information gain for this split. Use the threshold \\( T = 75 \\)\n","\n","To calculate the information gain, we need to split the dataset based on the threshold \\( T = 75 \\) and calculate the entropy of the resulting subsets.\n","\n","**Split based on Temperature \\( T = 75 \\):**\n","- Temperature ≤ 75: Samples 4, 5, 6\n","- Temperature > 75: Samples 1, 2, 3\n","\n","Let's calculate the entropy for each subset.\n","\n","**Subset where Temperature ≤ 75:**\n","- Samples: 4, 5, 6\n","- PlayTennis: Yes, Yes, No\n","\n","Entropy:\n","\n","$ p(Yes) = \\frac{2}{3} = 0.6667 $\n","\n","$ p(No) = \\frac{1}{3} = 0.3333 $\n","\n","$ H(S1) = - (0.6667 \\log_2 0.6667 + 0.3333 \\log_2 0.3333) $\n","\n","$ H(S1) = - (0.6667 \\times -0.585 + 0.3333 \\times -1.585) $\n","\n","$ H(S1) = - (-0.389 + -0.528) $\n","\n","$ H(S1) = 0.918 $\n","\n","**Subset where Temperature > 75:**\n","- Samples: 1, 2, 3\n","- PlayTennis: No, No, Yes\n","\n","Entropy:\n","\n","$ p(Yes) = \\frac{1}{3} = 0.3333 $\n","\n","$ p(No) = \\frac{2}{3} = 0.6667 $\n","\n","$ H(S2) = - (0.3333 \\log_2 0.3333 + 0.6667 \\log_2 0.6667) $\n","\n","$ H(S2) = - (0.3333 \\times -1.585 + 0.6667 \\times -0.585) $\n","\n","$ H(S2) = - (-0.528 + -0.389) $\n","\n","$ H(S2) = 0.918 $\n","\n","**Weighted Average Entropy:**\n","\n","$ H(S_T) = \\frac{3}{6} H(S1) + \\frac{3}{6} H(S2) $\n","\n","$ H(S_T) = 0.5 \\times 0.918 + 0.5 \\times 0.918 $\n","\n","$ H(S_T) = 0.918 $\n","\n","**Information Gain:**\n","\n","$ IG(S, Temperature) = H(S) - H(S_T) $\n","\n","$ IG(S, Temperature) = 1 - 0.918 $\n","\n","$ IG(S, Temperature) = 0.082 $\n","\n","### 3. Determine which attribute would be the best to split on first based on the highest information gain among the attributes Temperature, Humidity, and WindSpeed.\n","\n","Let's calculate the information gain for Humidity and WindSpeed using appropriate thresholds.\n","\n","**Information Gain for Humidity:**\n","\n","Choose a threshold for splitting Humidity. Use \\( H = 85 \\).\n","\n","**Split based on Humidity \\( H = 85 \\):**\n","- Humidity ≤ 85: Samples 1, 4, 5, 6\n","- Humidity > 85: Samples 2, 3\n","\n","**Subset where Humidity ≤ 85:**\n","- Samples: 1, 4, 5, 6\n","- PlayTennis: No, Yes, Yes, No\n","\n","Entropy:\n","\n","$ p(Yes) = \\frac{2}{4} = 0.5 $\n","\n","$ p(No) = \\frac{2}{4} = 0.5 $\n","\n","$ H(S1) = - (0.5 \\log_2 0.5 + 0.5 \\log_2 0.5) $\n","\n","$ H(S1) = - (0.5 \\times -1 + 0.5 \\times -1) $\n","\n","$ H(S1) = 1 $\n","\n","**Subset where Humidity > 85:**\n","- Samples: 2, 3\n","- PlayTennis: No, Yes\n","\n","Entropy:\n","\n","$ p(Yes) = \\frac{1}{2} = 0.5 $\n","\n","$ p(No) = \\frac{1}{2} = 0.5 $\n","\n","$ H(S2) = - (0.5 \\log_2 0.5 + 0.5 \\log_2 0.5) $\n","\n","$ H(S2) = - (0.5 \\times -1 + 0.5 \\times -1) $\n","\n","$ H(S2) = 1 $\n","\n","**Weighted Average Entropy:**\n","\n","$ H(S_H) = \\frac{4}{6} H(S1) + \\frac{2}{6} H(S2) $\n","\n","$ H(S_H) = \\frac{4}{6} \\times 1 + \\frac{2}{6} \\times 1 $\n","\n","$ H(S_H) = 1 $\n","\n","**Information Gain:**\n","\n","$ IG(S, Humidity) = H(S) - H(S_H) $\n","\n","$ IG(S, Humidity) = 1 - 1 $\n","\n","$ IG(S, Humidity) = 0 $\n","\n","**Information Gain for WindSpeed:**\n","\n","Choose a threshold for splitting WindSpeed. Use \\( W = 10 \\).\n","\n","**Split based on WindSpeed \\( W = 10 \\):**\n","- WindSpeed ≤ 10: Samples 1, 3, 4, 5\n","- WindSpeed > 10: Samples 2, 6\n","\n","**Subset where WindSpeed ≤ 10:**\n","- Samples: 1, 3, 4, 5\n","- PlayTennis: No, Yes, Yes, Yes\n","\n","Entropy:\n","\n","$ p(Yes) = \\frac{3}{4} = 0.75 $\n","\n","$ p(No) = \\frac{1}{4} = 0.25 $\n","\n","$ H(S1) = - (0.75 \\log_2 0.75 + 0.25 \\log_2 0.25) $\n","\n","$ H(S1) = - (0.75 \\times -0.415 + 0.25 \\times -2) $\n","\n","$ H(S1) = - (-0.31125 + -0.5) $\n","\n","$ H(S1) = 0.81125 $\n","\n","**Subset where WindSpeed > 10:**\n","- Samples: 2, 6\n","- PlayTennis: No, No\n","\n","Entropy:\n","\n","$ H(S2) = - (1 \\log_2 1) $\n","\n","$ H(S2) = 0 $\n","\n","**Weighted Average Entropy:**\n","\n","$ H(S_W) = \\frac{4}{6} H(S1) + \\frac{2}{6} H(S2) $\n","\n","$ H(S_W) = \\frac{4}{6} \\times 0.81125 + \\frac{2}{6} \\times 0 $\n","\n","$ H(S_W) = 0.540833 $\n","\n","**Information Gain:**\n","\n","$ IG(S, WindSpeed) = H(S) - H(S_W) $\n","\n","$ IG(S, WindSpeed) = 1 - 0.540833 $\n","\n","$ IG(S, WindSpeed) = 0.459167 $\n","\n","### Best Attribute to Split\n","\n","Comparing the information gains:\n","- \\( IG(S, Temperature) = 0.082 \\)\n","- \\( IG(S, Humidity) = 0 \\)\n","- \\( IG(S, WindSpeed) = 0.459167 \\)\n","\n","The best attribute to split on first is **WindSpeed**, with the highest information gain of 0.459167."],"metadata":{"id":"0AhevELjLFE3"}},{"cell_type":"markdown","source":["# Question 2: Calculating Information Gain for a Decision Tree Regression Problem\n","\n","You are given a dataset of numerical features and a target variable indicating the house prices. The dataset has the following attributes: Size (in square feet), Number of Bedrooms, and Age (in years). The target variable is Price (in $1000s). The dataset is as follows:\n","\n","| Size (sqft) | Bedrooms | Age (years) | Price ($1000s) |\n","|-------------|----------|-------------|----------------|\n","| 2100        | 3        | 30          | 400            |\n","| 1600        | 2        | 20          | 330            |\n","| 2400        | 4        | 15          | 369            |\n","| 1416        | 3        | 40          | 232            |\n","| 3000        | 4        | 8           | 540            |\n","| 1985        | 3        | 30          | 260            |\n","\n","1. **Calculate the variance of the target variable Price.**\n","\n","2. **Choose a threshold for splitting the attribute \"Size\" and calculate the information gain for this split. Use the threshold \\( S = 2000 \\) (i.e., split the data into subsets where Size ≤ 2000 and Size > 2000).**\n","\n","---\n","\n","### Solution Outline:\n","\n","1. **Variance of Price:**\n","\n","   Variance is calculated using the formula:\n","   $\n","   \\text{Var}(S) = \\frac{1}{N} \\sum_{i=1}^{N} (x_i - \\bar{x})^2\n","   $\n","   where \\(N\\) is the number of samples, \\(x_i\\) is the value of the target variable for the \\(i\\)-th sample, and $\\bar{x}$ is the mean of the target variable.\n","\n","2. **Information Gain for Size:**\n","\n","   - Split the dataset based on the threshold \\( S = 2000 \\).\n","   - Calculate the variance of each subset.\n","   - Calculate the weighted average variance of the subsets.\n","   - Information gain is calculated using the formula:\n","   $\n","   IG(S, A) = \\text{Var}(S) - \\sum_{v \\in \\text{Values}(A)} \\frac{|S_v|}{|S|} \\text{Var}(S_v)\n","   $\n","   where \\(S_v\\) is the subset of \\(S\\) for which attribute \\(A\\) has value \\(v\\).\n"],"metadata":{"id":"2iK6-zBTrQ4y"}},{"cell_type":"markdown","source":["# Solution\n","\n","### 1. Calculate the variance of the target variable Price\n","\n","The variance of the target variable can be calculated using the formula:\n","\n","$ \\text{Var}(S) = \\frac{1}{N} \\sum_{i=1}^{N} (x_i - \\bar{x})^2 $\n","\n","where \\(N\\) is the number of samples, \\(x_i\\) is the value of the target variable for the \\(i\\)-th sample, and \\(\\bar{x}\\) is the mean of the target variable.\n","\n","First, calculate the mean of the Price:\n","\n","$ \\bar{x} = \\frac{400 + 330 + 369 + 232 + 540 + 260}{6} $\n","\n","$ \\bar{x} = \\frac{2131}{6} $\n","\n","$ \\bar{x} \\approx 355.17 $\n","\n","Next, calculate the variance:\n","\n","$ \\text{Var}(S) = \\frac{1}{6} \\left[ (400 - 355.17)^2 + (330 - 355.17)^2 + (369 - 355.17)^2 + (232 - 355.17)^2 + (540 - 355.17)^2 + (260 - 355.17)^2 \\right] $\n","\n","$ \\text{Var}(S) = \\frac{1}{6} \\left[ 2004.31 + 637.22 + 189.22 + 15116.43 + 34112.87 + 9033.68 \\right] $\n","\n","$ \\text{Var}(S) = \\frac{1}{6} \\times 60993.73 $\n","$ \\text{Var}(S) \\approx 10165.62 $\n","\n","### 2. Information Gain for Size\n","\n","To calculate the information gain, we need to split the dataset based on the threshold \\( S = 2000 \\) and calculate the variance of the resulting subsets.\n","\n","**Split based on Size \\( S = 2000 \\):**\n","- Size ≤ 2000: Samples 2, 4, 6\n","- Size > 2000: Samples 1, 3, 5\n","\n","**Subset where Size ≤ 2000:**\n","- Prices: 330, 232, 260\n","\n","Mean:\n","\n","$ \\bar{x}_1 = \\frac{330 + 232 + 260}{3} = \\frac{822}{3} \\approx 274 $\n","\n","Variance:\n","\n","$ \\text{Var}(S_1) = \\frac{1}{3} \\left[ (330 - 274)^2 + (232 - 274)^2 + (260 - 274)^2 \\right] $\n","\n","$ \\text{Var}(S_1) = \\frac{1}{3} \\left[ 3136 + 1764 + 196 \\right] $\n","\n","$ \\text{Var}(S_1) = \\frac{5096}{3} $\n","\n","$ \\text{Var}(S_1) \\approx 1698.67 $\n","\n","**Subset where Size > 2000:**\n","- Prices: 400, 369, 540\n","\n","Mean:\n","\n","$ \\bar{x}_2 = \\frac{400 + 369 + 540}{3} = \\frac{1309}{3} \\approx 436.33 $\n","\n","Variance:\n","$ \\text{Var}(S_2) = \\frac{1}{3} \\left[ (400 - 436.33)^2 + (369 - 436.33)^2 + (540 - 436.33)^2 \\right] $\n","\n","$ \\text{Var}(S_2) = \\frac{1}{3} \\left[ 1303.91 + 4503.56 + 10777.96 \\right] $\n","\n","$ \\text{Var}(S_2) = \\frac{16605.43}{3} $\n","\n","$ \\text{Var}(S_2) \\approx 5535.14 $\n","\n","**Weighted Average Variance:**\n","\n","$ \\text{Var}(S_{\\text{Size}}) = \\frac{3}{6} \\times \\text{Var}(S_1) + \\frac{3}{6} \\times \\text{Var}(S_2) $\n","\n","$ \\text{Var}(S_{\\text{Size}}) = 0.5 \\times 1698.67 + 0.5 \\times 5535.14 $\n","\n","$ \\text{Var}(S_{\\text{Size}}) = 3397.57 $\n","\n","**Information Gain:**\n","\n","$ IG(S, \\text{Size}) = \\text{Var}(S) - \\text{Var}(S_{\\text{Size}}) $\n","\n","$ IG(S, \\text{Size}) = 10165.62 - 3397.57 $\n","\n","$ IG(S, \\text{Size}) = 6768.05 $\n","\n"],"metadata":{"id":"UVWOBOyEtaoe"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y7_gu34_Jumo"},"outputs":[],"source":[]}]}